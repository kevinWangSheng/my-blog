<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>线程 on Shawn在路上</title><link>https://kevinwangsheng.github.io/my-blog/tags/%E7%BA%BF%E7%A8%8B/</link><description>Recent content in 线程 on Shawn在路上</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 29 Nov 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://kevinwangsheng.github.io/my-blog/tags/%E7%BA%BF%E7%A8%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>线程</title><link>https://kevinwangsheng.github.io/my-blog/posts/%E7%BA%BF%E7%A8%8B/</link><pubDate>Sat, 29 Nov 2025 00:00:00 +0000</pubDate><guid>https://kevinwangsheng.github.io/my-blog/posts/%E7%BA%BF%E7%A8%8B/</guid><description>&lt;h1 id="线程"&gt;线程
&lt;/h1&gt;&lt;h2 id="物理层"&gt;物理层
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;CPU 的“真假”核心：物理核 vs 逻辑核&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当你买电脑时看到“8核16线程”，这到底意味着什么？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;物理核 (Physical Core)：这是真正的硬件单元，有独立的算术逻辑单元 (ALU) 和一级缓存。&lt;/li&gt;
&lt;li&gt;逻辑核 (Logical Core / Hyper-Threading)：这是 Intel/AMD 的一种“欺骗”技术。
✅ 调优启示：&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;如果你的程序是 计算密集型（加密、图像处理、矩阵运算），线程数应该接近 物理核数，而不是逻辑核数。设置过多线程只会增加切换开销，没有任何好处。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="2-存储墙与-cache-line性能优化的核心"&gt;2. 存储墙与 Cache Line（性能优化的核心）
&lt;/h3&gt;&lt;p&gt;CPU 的速度比内存快 100 倍以上。如果 CPU 每执行一条指令都要去内存拿数据，那 CPU 99% 的时间都在“摸鱼”。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，硬件引入了 多级缓存 (L1/L2/L3)。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L1 Cache：最快，私有（每个核独享）。&lt;/li&gt;
&lt;li&gt;L2 Cache：很快，私有（或两核共享）。&lt;/li&gt;
&lt;li&gt;L3 Cache：较快，共享（所有核共享）。&lt;/li&gt;
&lt;li&gt;主内存 (RAM)：非常慢。
⚠️ 关键概念：Cache Line (缓存行)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这是绝大多数程序员忽略的地方。CPU 从内存读取数据，不是一个字节一个字节读的，而是一块一块读的。 这一块通常是 64 Bytes。&lt;/p&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;p&gt;你需要读取一个 int a (4 bytes)。CPU 会把包含 a 的周边 64 字节的数据一次性全搬到缓存里。&lt;/p&gt;
&lt;h3 id="3-伪共享-false-sharing多线程的隐形杀手"&gt;3. 伪共享 (False Sharing)：多线程的隐形杀手
&lt;/h3&gt;&lt;p&gt;既然大家是按块（Cache Line）读取的，灾难就来了。&lt;/p&gt;
&lt;p&gt;场景：&lt;/p&gt;
&lt;p&gt;内存中有两个变量 x 和 y，它们紧挨着。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程 A 运行在 核 1，它只修改 x。&lt;/li&gt;
&lt;li&gt;线程 B 运行在 核 2，它只修改 y。
逻辑上，它们互不干扰。但在物理上，它们如果在 同一个 Cache Line 里：&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;核 1 修改了 x -&amp;gt; 核 1 的缓存行变脏 (Dirty)。&lt;/li&gt;
&lt;li&gt;根据 MESI 协议（缓存一致性协议），核 1 必须通知核 2：“嘿，这个缓存行废了（Invalid）！”&lt;/li&gt;
&lt;li&gt;核 2 想要修改 y，发现缓存行废了，必须强制重新从内存加载。&lt;/li&gt;
&lt;li&gt;核 2 修改 y -&amp;gt; 通知核 1 缓存失效。&lt;/li&gt;
&lt;li&gt;死循环：两个核像打乒乓球一样争抢这个缓存行的控制权。
结果：性能暴跌 10 倍以上，且 CPU 利用率很高（忙着同步缓存），但没干正事。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;✅ 调优/代码启示：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;缓存行填充 (Padding)：在 x 和 y 之间塞入 56 字节的无用数据（凑够 64 字节），强制让它们分布在不同的 Cache Line 里。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="4-指令重排序-instruction-reordering乱序执行"&gt;4. 指令重排序 (Instruction Reordering)：乱序执行
&lt;/h3&gt;&lt;p&gt;你以为 CPU 是老老实实按你写的代码顺序执行的吗？不是。&lt;/p&gt;
&lt;p&gt;为了性能，CPU 会 乱序执行 (Out-of-Order Execution)。&lt;/p&gt;
&lt;p&gt;代码：&lt;/p&gt;
&lt;p&gt;codeText&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;a = 1;&lt;/li&gt;
&lt;li&gt;b = 2;&lt;/li&gt;
&lt;li&gt;c = a + b;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CPU 视角：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第 3 步依赖 1 和 2，必须最后做。&lt;/li&gt;
&lt;li&gt;但是 1 和 2 谁先谁后无所谓。&lt;/li&gt;
&lt;li&gt;如果 a 在内存里（慢），b 已经在缓存里（快），CPU 会先执行 2，再执行 1，最后执行 3。
多线程下的灾难：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在单线程下，这种乱序不影响结果。但在多线程下，另一个线程可能在某个时间点看到 b=2 但 a=0（还没赋值）。这打破了我们逻辑上的因果关系。&lt;/p&gt;
&lt;p&gt;✅ 调优/代码启示：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这就是为什么上层语言需要 内存屏障 (Memory Barrier/Fence)。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="os--kernel"&gt;OS Kernel
&lt;/h2&gt;&lt;p&gt;在这一层，一切皆是 “任务” (Task)。内核并不太关心你是 Java 写的还是 C 写的，它只关心怎么把时间分片。&lt;/p&gt;
&lt;h3 id="1-进程-process-vs-线程-thread-的内核视角"&gt;1. 进程 (Process) vs 线程 (Thread) 的内核视角
&lt;/h3&gt;&lt;p&gt;教科书上说“进程是资源分配单位，线程是调度单位”。我们要看透本质：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;虚拟内存：每个 进程 都有一个独立的“幻觉”，以为自己独占 4GB（或更多）内存。这是通过 页表 (Page Table) 映射实现的。&lt;/li&gt;
&lt;li&gt;共享与隔离：
内核结构 (Linux 为例)：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Linux 内核里，线程其实是 轻量级进程 (LWP)。它们都有自己的 task_struct，唯一的区别是线程之间共享了内存地址空间（mm_struct）。&lt;/p&gt;
&lt;h3 id="2-上下文切换-context-switch并发的隐形税"&gt;2. 上下文切换 (Context Switch)：并发的隐形税
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;当你启动 1000 个线程，而 CPU 只有 4 个核时，OS 必须不断地把旧线程踢下去，换新线程上来。这个过程叫 上下文切换。&lt;/p&gt;
&lt;p&gt;这不是免费的，而且很贵。&lt;/p&gt;
&lt;p&gt;切换过程详解：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;暂停：挂起当前线程。&lt;/li&gt;
&lt;li&gt;保存：把 CPU 寄存器里的值（PC指针、栈指针、通用寄存器）存回内存（内核栈）。&lt;/li&gt;
&lt;li&gt;调度：运行调度算法，决定下一个选谁。&lt;/li&gt;
&lt;li&gt;加载：把下一个线程的寄存器值从内存读回 CPU。&lt;/li&gt;
&lt;li&gt;恢复：开始执行。
真正的代价在哪里？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;除了上述 CPU 指令的开销（微秒级），最大的代价是 缓存污染 (Cache Pollution)：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程 A 跑得正欢，L1/L2 缓存里全是它的热数据。&lt;/li&gt;
&lt;li&gt;突然被切走，换线程 B 上来。&lt;/li&gt;
&lt;li&gt;线程 B 把缓存填满它的数据。&lt;/li&gt;
&lt;li&gt;线程 A 再次回来时，发现缓存全空了（Cache Miss），必须重新去慢速内存读。&lt;/li&gt;
&lt;li&gt;性能暴跌。
✅ 调优启示：&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;避免过度切换：如果你的线程数远大于核心数，且任务都很短，CPU 可能花在“切换”上的时间比“干活”的时间还多。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="3-调度器-schedulercfs-的秘密"&gt;3. 调度器 (Scheduler)：CFS 的秘密
&lt;/h3&gt;&lt;p&gt;OS 怎么决定下一个运行谁？Linux 默认使用的是 CFS (Completely Fair Scheduler，完全公平调度器)。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;红黑树：CFS 用一棵红黑树来管理所有等待运行的线程。&lt;/li&gt;
&lt;li&gt;vruntime (虚拟运行时间)：&lt;/li&gt;
&lt;li&gt;优先级 (Nice 值)：
抢占 (Preemption)：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果一个线程跑太久了，或者有一个更高优先级的线程醒了（比如网卡收到了数据），内核会通过 时钟中断 强行把当前线程踢下去。这就是“抢占式调度”。&lt;/p&gt;
&lt;h3 id="4-内核态-kernel-mode-vs-用户态-user-mode"&gt;4. 内核态 (Kernel Mode) vs 用户态 (User Mode)
&lt;/h3&gt;&lt;p&gt;这是执行流中最常见的“边界”。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户态：你的代码跑的地方，权限受限，不能直接碰硬件。&lt;/li&gt;
&lt;li&gt;内核态：OS 核心代码跑的地方，拥有最高权限。
系统调用 (Syscall)：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当你的线程想写文件、发网络包、甚至申请内存时，必须执行 syscall 指令，从用户态跳进内核态。&lt;/p&gt;
&lt;p&gt;为什么它慢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;切换开销：需要保存用户态寄存器，切换堆栈。&lt;/li&gt;
&lt;li&gt;安全检查：内核必须检查你的参数合不合法。&lt;/li&gt;
&lt;li&gt;Meltdown/Spectre 补丁：为了防 CPU 漏洞，现代 CPU 在这个边界上的切换成本变得更高了（强制刷新 TLB）。
✅ 调优启示：&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;减少 Syscall：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="5-cpu-亲和性-cpu-affinity"&gt;5. CPU 亲和性 (CPU Affinity)
&lt;/h3&gt;&lt;p&gt;还记得第一章的 Cache Line 吗？&lt;/p&gt;
&lt;p&gt;如果线程 A 上一次在 Core 1 跑，缓存里都是热数据。下一次调度时，如果 OS 把它调度到了 Core 2，那 Core 1 的热缓存就白费了，Core 2 还要重新预热。&lt;/p&gt;
&lt;p&gt;亲和性就是 OS 尽量让线程回到上次跑的那个核上。&lt;/p&gt;</description></item></channel></rss>